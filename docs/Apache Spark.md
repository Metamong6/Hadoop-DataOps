## Spark

### What is Apache Spark?

⇒ 아파치 스파크(apache spark)는 2011년 버클리 대학의 AMPLab에서 개발되어 현재는 아파치 재단의 오픈소스로 관리되고 있는 **인메모리 기반의 대용량 데이터 고속 처리 엔진**으로 **범용 분산 클러스터 컴퓨팅 프레임워크**입니다.

### **특징**

스파크의 특징은 다음과 같습니다.

- **Speed**
    - 인메모리(In-Memory) 기반의 빠른 처리
- **Ease of Use**
    - 다양한 언어 지원(Java, Scala, Python, R, SQL)을 통한 사용의 편이성
- **Generality**
    - SQL, Streaming, 머신러닝, 그래프 연산 등 다양한 컴포넌트 제공
- **Run Everywhere**
    - YARN, Mesos, Kubernetes 등 다양한 클러스터에서 동작 가능
    - HDFS, Casandra, HBase 등 다양한 파일 포맷 지원

각 특징에 대해서 알아보겠습니다.

### **인메모리 기반의 빠른 처리**

스파크는 인메모리 기반의 처리로 맵리듀스 작업처리에 비해 디스크는 10배, 메모리 작업은 100배 빠른 속도를 가지고 있습니다. 맵리듀스는 작업의 중간 결과를 디스크에 쓰기 때문에 IO로 인하여 작업 속도에 제약이 생깁니다. 스파크는 메모리에 중간 결과를 메모리에 저장하여 반복 작업의 처리 효율이 높습니다. 물론 현재로서는 서로의 장단점을 받아들여서 둘 다 훌륭한 툴로써 쓰이고 있습니다.

![Untitled](https://user-images.githubusercontent.com/102719063/203532065-13487707-6436-4c4c-8bad-f02c5842d48f.png)

그림출처 : [https://data-flair.training/blogs/spark-vs-hadoop-mapreduce/](https://data-flair.training/blogs/spark-vs-hadoop-mapreduce/)

### **다양한 컴포넌트 제공**

스파크는 단일 시스템 내에서 스파크 스트리밍을 이용한 스트림 처리, 스파크 SQL을 이용한 SQL 처리, MLib 를 이용한 머신러닝 처리, GraphX를 이용한 그래프 프로세싱을 지원합니다. 추가적인 소프트웨어의 설치 없이도 다양한 애플리케이션을 구현할 수 있고, 각 컴포넌트간의 연계를 이용한 애플리케이션의 생성도 쉽게 구현할 수 있습니다.

### **다양한 언어 지원**

스파크는 자바, 스칼라, 파이썬, R 인터페이스등 다양한 언어를 지원하여 개발자에게 작업의 편의성을 제공합니다. 하지만 언어마다 처리하는 속도[2](https://wikidocs.net/26513#fn:2)가 다릅니다. 따라서 성능을 위해서는 Scala 로 개발을 진행하는 것이 좋습니다.

### **다양한 클러스터 매니저 지원**

클러스터 매니저로 YARN, Mesos, Kubernetes, standalone 등 다양한 포맷을 지원하여 운영 시스템 선택에 다양성을 제공합니다. 또한, HDFS, 카산드라, HBase, S3 등의 다양한 데이터 포맷을 지원하여 여러 시스템에 적용이 가능합니다.

### **다양한 파일 포맷 지원 및 Hbase, Hive 등과 연동 가능**

스파크는 기본적으로 TXT, Json, ORC, Parquet 등의 파일 포맷을 지원합니다. S3, HDFS 등의 파일 시스템과 연동도 가능하고, HBase, Hive 와도 간단하게 연동할 수 있습니다.

### 단점

데이터 셋이 적어서 단일 노드로 충분한 애플리케이션에서 스파크는 분산 아키텍처로 인해 오히려 성능이 떨어집니다. 또한 대량의 트랜잭션을 빠르게 처리해야 하는 애플리케이션은 스파크가 온라인 트랜잭션 처리를 염두에 두고 설계되지 않았기 때문에 유용하지 않습니다.

### Yarn on Spark

YARN이 클러스터 매니저 역할을 하는 형태입니다. 리소스가 할당되는 과정은 다음과 같습니다. (어플리케이션 종류가 스파크일 뿐, YARN 개념이 동일하게 적용됩니다.)

(1) 클라이언트가 스파크 어플리케이션을 리소스 매니저에게 제출합니다.

(2) 리소스 매니저는 노드매니저 중 하나를 선정해서 어플리케이션 마스터(스파크 driver)를 실행할 컨테이너를 할당하라고 지시합니다.

(3) 노드매니저는 어플리케이션 마스터(스파크 driver)의 컨테이너를 시작합니다.

(4) 어플리케이션 마스터는 스파크 executor에 사용할 컨테이너들을 리소스 매니저에 추가로 요청합니다.

(5) 리소스 매니저가 리소스 할당을 ok 하면, 어플리케이션 마스터는 노드매니저에게 컨테이너를 시작하라고 합니다.

(6) 노드매니저는 스파크 executor에서 사용할 컨테이너를 시작합니다.

(7) 이제 driver와 executor는 직접 통신하면서 스파크 어플리케이션을 수행합니다.

### **스파크 히스토리 서버Spark History Server**

- 실행중인 작업과 실행이 끝난 작업의 히스토리를 확인하기 위한 서버
- `start-history-server.sh`로 실행하고 기본 접속 포트는 `18080`
- 영구적인 저장소에 스파크 작업 내역을 저장 하고 사용자의 요청에 정보를 반환

### PySpark

⇒ ***PySpark***는 Apache Spark와 Python의 공동 작업을 지원하기 위해 릴리스되었으며, 사실상 Spark용 Python API의 일종입니다.

Apache Spark는 Scala 프로그래밍 언어로 작성되었습니다.

PySpark는 Apache Spark와 Python의 공동 작업을 지원하기 위해 릴리스되었으며, 사실상 Spark용 Python API의 일종입니다. 또한 PySpark를 사용하면 Apache Spark와 Python 프로그래밍 언어로 RDD(Resilient Distributed Datasets)에 접속하는 데 도움이 됩니다. 이를 위해 Py4j 라이브러리를 활용했습니다. 
Py4J는 PySpark에 내장된 대중적인 라이브러리이며 JVM 개체를 사용해 Python의 동적인 인터페이스를 허용합니다. PySpark에는 효율적인 프로그램을 쓰는 데 좋은 라이브러리가 꽤 많습니다. 또한 호환되는 외부 라이브러리도 다양합니다.

**PySparkSQL**

엄청난 대량의 구조적 또는 반구조적 데이터에 SQL 유사 분석을 적용하는 데 쓰이는 PySpark 라이브러리입니다. PySparkSQL은 SQL 쿼리에도 사용할 수 있습니다. 또한 Apache Hive 에 연결할 수도 있습니다. HiveQL을 적용해도 됩니다. PySparkSQL은 PySpark 코어를 통한 래퍼(wrapper)입니다. PySparkSQL은 DataFrame을 도입했는데, 이것은 관계형 데이터베이스 관리 시스템의 테이블과 비슷한 구조적 데이터의 테이블 형식 표현입니다.

**MLlib**

MLlib은 PySpark를 통한 래퍼(wrapper)이며 Spark의 머신 러닝(ML) 라이브러리이기도 합니다. 이 라이브러리는 데이터 병렬 처리 기법을 사용하여 데이터를 저장하고 다룹니다. MLlib 라이브러리가 제공하는 머신 러닝 API는 사용이 무척 간편합니다. MLlib은 수많은 머신 러닝 알고리즘을 지원하여 분류, 회귀, 클러스터링, 공동 작업 필터링, 차원 감소 및 기본 최적화 기본 형식(primitive) 등에 사용할 수 있습니다.

**GraphFrame**

GraphFrame은 특수 제작한 그래프 처리 라이브러리로, 일련의 API를 제공하여 그래프 분석을 효율적으로 수행합니다. 이때 PySpark와 PySparkSQL을 사용합니다. 고속 분산형 컴퓨팅에 최적화되어 있습니다. 

**PySpark를 사용하여 얻을 수 있는 장점:** 

- Python을 매우 손쉽게 배우고 구현할 수 있습니다.
- 단순하고 종합적인 API를 제공합니다.
- Python과 함께 사용하면 코드의 가독성, 유지와 친숙도가 훨씬 나아집니다.
- 데이터 시각화를 위한 다양한 옵션을 제공하는데, 데이터 시각화는 Scala나 Java로는 어렵습니다.

### Trouble shooting:

- 🙄 spark on yarn → why spark?
    
    리소스를 할당하고 얀 (하둡의 모든 리소스 관리) 어플리케이션 마스터 → 어플리케이션 마스터가 필요한 리소스 감지 → 노드매니저 한테 잡을 뿌림 → 노드매니저들이 잡을 수행한다.
    : 스파크 클러스터 쓸 필요없음. 현재로서는 Spark history server, PySpark 용도로 사용 중. 하지만 이후에 확장 가능 있음.
